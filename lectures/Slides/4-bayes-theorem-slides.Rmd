---
title: "Bayes' Theorem"
author: "Eric Scott"
date: "2020-1-23"
output:
  powerpoint_presentation:
    reference_doc: template.pptx
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 5)
source(here::here("plot_theme.R"))
library(tidyverse)
library(knitr)
options(scipen = 999)
```

```{r include=FALSE}
#do all the calculations up front.
s <- seq(0.1, 0.9, 0.1)
orchid_lg_lik <- s^8 * (1-s)^2

df <- tibble(`survival probability` = s,
                   `P(data|model)` = orchid_lg_lik)

df_un <- df %>% 
  mutate(`P(model)` = 1/n()) %>% 
  mutate(numerator = `P(data|model)` * `P(model)`) %>% 
  mutate(`P(model|data)` = `P(data|model)` * `P(model)` / sum(numerator))

df_inf <- df %>% 
  mutate(`P(model)` = c(rep(0.1, 5), 0.2, rep(0.1, 3))) %>% 
  mutate(numerator = `P(data|model)` * `P(model)`) %>% 
  mutate(`P(model|data)` = `P(data|model)` * `P(model)` / sum(numerator))

  
## Plots

lik_plot <- ggplot(df_un, aes(x = `survival probability`, y = `P(data|model)`)) +
  geom_point(color = "orange") +
  geom_line(color = "orange") +
  labs(title = "Likelihood of model|data") + 
  scale_x_continuous(breaks = seq(0.1, 0.9, 0.1))

prior_un <- ggplot(df_un, aes(x = `survival probability`, y = `P(model)`)) +
    geom_point(color = "blue") +
  geom_line(color = "blue") +
  labs(title = "Uninformative prior") +
  scale_x_continuous(breaks = seq(0.1, 0.9, 0.1))

prob_un <- ggplot(df_un, aes(x = `survival probability`, y = `P(model|data)`)) +
  geom_point(color = "green") +
  geom_line(color = "green") +
  labs(title = "Probability of model|data") +
  scale_x_continuous(breaks = seq(0.1, 0.9, 0.1))

prior_inf <- ggplot(df_inf, aes(x = `survival probability`, y = `P(model)`)) +
    geom_point(color = "blue") +
  ylim(0,0.25) +
  geom_line(color = "blue") +
  labs(title = "Informative prior") +
  scale_x_continuous(breaks = seq(0.1, 0.9, 0.1))

prob_inf <- ggplot(df_inf, aes(x = `survival probability`, y = `P(model|data)`)) +
  geom_point(color = "green") +
  geom_line(color = "green") +
  labs(title = "Probability of model|data (informative prior)") +
  scale_x_continuous(breaks = seq(0.1, 0.9, 0.1))
```

## Bayes' Theorem Continued

$$
P(B│A)=  \frac{(P(A│B)P(B))}{(P(A))} → P(model│data) = \frac{(P(data│model)P(model))}{(P(data))}
$$
- Back to the perennial flower example...

- We have already calculated P(data|model) for our simple plant demography example

```{r echo=FALSE}
kable(df)
```

## Priors

What is P(model), the "prior probability"?

- the probability of each possible model *prior to* collection or analysis of the data being analyzed.  
- In many cases, we want to base inference **only** on our data, in whcih case we use **uninformative priors**
- for *j* models, each P(model) is 1/*J*
- This differs from our Lyme disease example, where we had **informative priors**

```{r echo=FALSE}
df_un %>% select(`survival probability`, `P(data|model)`, `P(model)`) %>% kable()
```
```{r}
prior_un
```


## What is P(data)?

- Assume all possible and mutually exclusive models are considered in the set of *j* models.  For each model, calculate P(data|model)*P(model) and sum over all j models. (OR rule)

$$
P(data) = \sum_{j=1}^nP(data|model_j)\times P(model_j)
$$
```{r echo=FALSE}
df_un %>% select(-`P(model|data)`) %>% kable()
```

```{r}
p_data <- sum(df_un$numerator)
p_data
```

## Apply Bayes' Theorem

```{r echo=FALSE}
df_un %>% kable()
```


- Remember, when priors are uninformative, P(model)  = 1/*j* and Bayes' Theorem begins to resemble likelihood:

$$
P(model|data) = P(data|model)\times \frac{(1/j)}{c}
$$
```{r}
lik_plot
prob_un
```

## With Informative Priors

```{r}
df_inf %>% select(-numerator, -`P(model|data)`) %>% kable()
```

```{r}
prior_inf
```

## next

```{r}
df_inf %>% select(-`P(model|data)`) %>% kable()
```

## next slide
```{r}
df_inf %>% kable()
df_inf$numerator %>% sum()
```

```{r}
prob_inf
```


