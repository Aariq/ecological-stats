---
title: "Likelihood and Bayes' Theorem"
author: "Eric Scott"
date: "2020-1-23"
output:
  powerpoint_presentation:
    reference_doc: template.pptx
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 5)
source(here::here("plot_theme.R"))
```

## Short problem from the end of last class (…ppt)

Ignoring flowering (for now), explore the likelihood of different values of survival, given the 5-plant data set.

a. Calculate the likelihood of survival having each of the following values: 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9.
b. Make a graph of the log-likelihood (y-axis) vs. value of survival (x-axis).
c. Repeat a & b for the 10-plant data set.  How does the shape of the graph change?
d. What is the likelihood that survival is 0?  Or 1? What happens to the log-likelihood at these values?
  
## Likelihood calculations

For small dataset:

```{r}
s <- seq(from = 0.1, to = 0.9, by = 0.1) #vector of possible values for s

# 4 survive, 1 doesn't survive. Math vectorized over all values of s
orchid_sm_lik <- s^4 * (1 - s) 

orchid_sm_lik
```

## Likelihood calculations

For larger dataset:

```{r}
orchid_lg_lik <- s^8 * (1-s)^2
orchid_lg_lik
```

## Plotting Likelihood Profiles

```{r include=FALSE}
df <-
  data.frame(
    dataset = c(rep("small", 9), rep("large", 9)), #column indicating which dataset
    s = c(s,s), #x-axis values
    likelihood = c(orchid_sm_lik, orchid_lg_lik)
  )
# knitr::kable(df)
```

```{r echo=FALSE}
library(ggplot2)
p <- ggplot(df, aes(x = s, y = likelihood, color = dataset)) +
  geom_point() +
  geom_line() +#add connecting lines
  labs(title = "Likelihood of hypothesis | data",
       x = "hypothesized probability of survival",
       y = "(relative) likelihood")
p
```

## Plot both side by side

```{r echo=FALSE}
p + facet_wrap(~dataset, scales = "free_y", ncol = 1)
```

## Plot log-likelihood

```{r echo=FALSE}
p2 <- ggplot(df, aes(x = s, y = log(likelihood), color = dataset)) +
  geom_point() +
  geom_line() +#add connecting lines
  labs(title = "Likelihood of hypothesis | data",
       x = "hypothesized probability of survival",
       y = "(relative) log-likelihood")
p2
```

## Question 2

a. What is $P(B|A)$ for two mutually exclusive events?  Is it possible for events to be independent and mutually exclusive?
    - $P(B|A)=0$ because there is no overlap.  Not possible for events to be independent and mutally exclusive. E.g. heads & tails aren't independent.
    
b. What is the probability that A **or** B occurs if they are **not** mutually exclusive?
    - $P(A+B) = P(A) + P(B) - P(A,B)$

## Homework 1

**My homework...**

- Wanted to estimate the occurrance of leafhoppers (a pest insect) on a tea plant.  
- I sampled the second leaf from the top (systematic) on haphazardly chosen shoots.
- In reality, I *counted* the number of leafhoppers
- In reality, I did this on multiple, randomly sampled plants

## My Data

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(here)
sampling_raw <- read_csv(here("lab", "data", "sampling effort.csv"))

sampling <- sampling_raw %>%
  # select("count" = area1) %>% 
  gather(key = "plant", value = "count") %>% 
  mutate(plant = str_remove(plant, "area"),
         "presence" = count > 0) %>% 
  filter(!is.na(count))
knitr::kable(head(sampling, 15))
```

## Calculate probability

```{r echo=FALSE}
probability <-
  sampling %>% 
  group_by(plant) %>% 
  mutate(trials = 1:n(),
         events = cumsum(presence),
         P_leafhopper = events/trials)
knitr::kable(head(probability, 15))
```

## Plot

```{r echo=FALSE}
ggplot(probability %>% filter(plant == "1"), aes(x = trials, y = P_leafhopper)) +
  geom_point(size = 0.5) +
  geom_line(alpha = 0.5) +
  geom_hline(aes(yintercept = 0.08), color = "blue") +
  ylim(0, 1) +
  labs(x = "# of trials (# of leaves observed)",
       y = "Estimated prob. of leafhopper")
```

## Plot with all plants

```{r echo=FALSE}
ggplot(probability, aes(x = trials, y = P_leafhopper, color = plant)) +
  geom_point(size = 0.5) +
  geom_line(alpha = 0.5) +
  # geom_hline(aes(yintercept = 0.08), color = "blue") +
  # ylim(0, 1) +
  labs(x = "# of trials (# of leaves observed)",
       y = "Estimated prob. of leafhopper") +
  theme(legend.position = "none") #removes legend
```

## Exponents and logarithms (from previous notes)

- review from last time

## Review

So far three major conceptual points:

1. Using data to estimate parameters (in this case, the survival and flowering probabilities of plants)
2. Calculating the probability of collecting a particular data set if a particular model were true ($P(data|model)$)
3. Calculating *likelihood* (relative support) for a model, given a data set

## Intro to Bayes' Theorem

Calculating the **probability** (absolute support) a model is “true”, given a dataset

Rev. Thomas Bayes (1702-1761) showed that we can convert the probability of seeing a particular data set, given a model and parameters, into the probability of the model and parameters, given the data:

## Bayes' Theorem

[derivation on board]

$$
P(model|data) = \frac{P(data|model) P(model)} {P(data)}
$$

$P(model|data)$ = probability of model and parameters, given the data
$P(data)$ = constant specific to the data set
$P(model)$ = sometimes controversial “prior probability”

## Simple intuitive example: testing for Lyme Disease

- We have tests for Lyme disease, so why shouldn't everyone get tested regularly?

    - true positive rate = 87%
    - false positive rate = 1% 
    - (these numbers actually vary depending on the type of test)

- But Lyme Disease is pretty rare in the US.  According to the CDC, about 300,000 cases per year
- 300,000 / 300,000,000 = 0.001, or about 0.1% of population

## Use Bayes' Theorem

$$
P(Lyme|+) = \frac{P(+|Lyme)\times P(Lyme)}{P(+)}
$$

Or in English:

The probabilty of having Lyme given a positive test equals the true positive rate of the test times the probability of getting Lyme divided by the probability of getting a positive test result (regardless of whether you have Lyme).

:::
You can also look at it like the probability of getting a true positive (this model) out of all the ways of getting a positive (both models) adjusted for the actual prevalence of Lyme (your prior belief of how likely it is that anyone would have Lyme).
:::

## Defining the terms:

- The "data" in this case, is a positive test result
- The "model" or "hypothesis" is "infected with Lyme disease".  There are two possible, mutually exclusive models: has/does not have lyme.
- $P(data|model)$ is given to us. But we've calculated this before (we'll come back to the orchid example later).

## Defining the terms:

- $P(model) = P(Lyme)$ is our prior probability, or $P(H)$ before considering the data.

- $P(data) = P(+)$ All possibilities that match the data. 

- $P(data) = P(data|model)\times P(model)$ summed over all (mutually exclusive) models.  [“OR” axiom of probability]

- Only two models in this case (lyme or no lyme).

## Calculations

$$
P(Lyme|+) = \frac{P(+|Lyme)\times P(Lyme)}{P(+|Lyme)P(Lyme) + P(+|\textit{no Lyme})P(\textit{no Lyme})}
$$

$P(+|Lyme)$ is the true positive rate and $P(+|uninfected)$ is the false positive rate.

$$
P(Lyme|+) =\frac{0.87 \times 0.001}{0.87 \times 0.001 + 0.01 \times 0.999}
$$

```{r}
p_lyme_pos = (0.87 * 0.001) / ((0.87 * 0.001) + (0.01 * 0.999))
p_lyme_pos
```

Only an 8% chance you have Lyme given a positive result!!

## What if we change our prior belief?

What would change if you knew the patient lived in Massachussetts? 

- Re-calculate with prior relevant to MA

## P(Lyme|+) for MA

87,000 Lyme cases / 6.5 million = 0.013

```{r}
(0.87 * 0.013) / ((0.87 * 0.013) + (0.1 * 0.987))
```

- What if they were in MA, bitten by a tick, AND had a bulls-eye rash?

```{r}
(0.87 * 0.6) / ((0.87 * 0.6) + (0.1 * 0.4))
```

## More on P(model), the “prior probability”?

- The probability of each possible model prior to collection or analysis of the data being analyzed.  

- **Informative priors** mean that all models are not equally likely, prior to collecting the data that will be explicitly incorporated into a statistical analysis. 

- Developing informative prior probabilities is a large, active, controversial and mathematically and computationally dense field of research.

- In many cases, we want to base inference *only* on data
    - if we compare $j$ possible models, the prior probability of each is $1/j$.  
    - This is called an **uninformative prior**.

## More on P(data)

In Bayesian analysis, we typically ASSUME all possible mutually-exclusive models are considered in the finite set of $j$ models we are comparing, and therefore:

$$
P(data) = \sum_{j=1}^nP(data|model_j)\times P(model_j)
$$

- This definition of $P(data)$ means that the sum of the $P(model_j)$ over all $j$ models must be 1.  

## Comparing to Likelihood

- $P(data)$ constant for a given dataset, so, from a practical perspective, Bayes’ $P(model)$ begins to resemble **likelihood** when there are **uninformative priors**:

$$
P(model|data) = \frac{P(data|model)\times (1/j)}{c}
$$

- $1/j$ is the [uninformative prior] probability of the model
- $P(data)$ is a constant, $c$, that is the sum of the $P(data|model) \times (1/j)$ over “all” models
    - note that because $P(data|model)$ is in the equation it is specific to the particular data set(!)
- $L(parameters (\theta)|data) = P(data|model, parameters) \times k$
- These are identical if $k = 1/jc$

## More on P(model|data)

- Also called "posterior probability".  The probability of the model *after* seeing the evidence (as opposed to "prior probability")

## In other words:

- In Bayesian analysis, we explicitly estimate the constant relating the probability of the model, given the data.  This means we can obtain an **absolute** measure of support for a model **IF** we are willing to believe we have searched all possible models.
- In likelihood analysis, we simply use the fact that the likelihood of a model given the data is proportional to the probability of the data given a model, and restrict our analyses to comparing the **relative** support for two or more models.
- The symmetry of the two metrics of support falls apart if $P(model|data)$ includes an *informative* prior probability distribution, rather than the constant *1/j*.

## Graphical / geometric representation

- Good video here: https://youtu.be/HZGCoVF3YvM